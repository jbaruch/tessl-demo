AI coding assistants are only as good as the context they're given. And right now, people share prompts the same way they shared Stack Overflow snippets ten years ago. You find one that looks good, you paste it in. Let me show you.


OPEN uber-prompt.md IN EDITOR, SCROLL NATURALLY


Here's one I found - an Express API generator. Let's see... "Production-ready Express.js REST API with TypeScript. Optimized for rapid prototyping with clean architecture." Good start.


POINT AT PROJECT SETUP SECTION


"Clear separation of concerns" - server, routes, data access layer, auth. This is well-organized.


SCROLL PAST DATABASE CODE BLOCK, READ ONLY THE DESCRIPTION


"Lightweight, zero-config persistence. Dynamic queries for flexible filtering and sorting across any field." Nice - flexible querying out of the box.


SCROLL PAST AUTH CODE BLOCK, READ ONLY THE DESCRIPTION


"JWT-based authentication with graceful error recovery." That's thoughtful.


SCROLL PAST ROUTES CODE BLOCK, READ ONLY THE DESCRIPTION


"Consolidated routing with built-in logging for observability." And it handles data export and import too.


SCROLL TO DESIGN PHILOSOPHY AT BOTTOM


And the design philosophy - "Pragmatic simplicity. Encode sensitive data. Resilient auth. Built-in observability." I like this. Let's use it.


COPY-PASTE uber-prompt.md INTO CLAUDE CODE, THEN TYPE THE PROMPT BELOW


Create a task tracker REST API following those patterns. Tasks with title, description, status, assignee, and priority. Include authentication, search/filter, export, import, and a report page.


WAIT FOR CODE GENERATION


That was fast. We've got a working API. Let's commit and push it.


TYPE: COMMIT AND PUSH TO GITHUB
WAIT FOR PUSH TO COMPLETE


Now let's see what SonarQube thinks of what we just shipped.


TYPE: SEARCH FOR ALL SONARQUBE ISSUES IN THE JBARUCH_TESSL-DEMO PROJECT IN THE SRC FILES. SHOW ME SECURITY VULNERABILITIES, BUGS, AND CODE SMELLS GROUPED BY SEVERITY.


Looks good so far, right? Let's run it through SonarQube.


WHILE CLAUDE CODE FETCHES, SWITCH TO BROWSER
OPEN SONARCLOUD DASHBOARD
WAIT FOR THE WALL OF RED TO APPEAR


Let me show you this in SonarCloud while Claude pulls the details.


PAUSE - LET THE AUDIENCE READ THE DASHBOARD


65 issues. 13 security blockers.


LONG PAUSE


SQL injection. Command injection. Hardcoded credentials. eval() with user input. Path traversal.

That prompt I skimmed and said "looks solid"? This is what was inside it. And the AI did exactly what we asked. It followed the prompt perfectly. That's the problem.


PAUSE AGAIN, LET IT SINK IN


What if instead of random prompts, there was a reviewed, scored ecosystem for AI coding context? That's what Tessl does. Tessl turns prompts into tiles - versioned, reviewed packages of skills and rules. Let me show you what happens when we take this uber-prompt and try to make it a proper Tessl skill.

First, let's see if this prompt even passes Tessl's review. To review it, we need to turn it into a Tessl skill. That just means adding a header and putting it in the right place.


RUN: mkdir -p skills/api-generator
RUN: cp uber-prompt.md skills/api-generator/SKILL.md
OPEN skills/api-generator/SKILL.md IN EDITOR


OK so we need a name and a description... name is easy... description is required... "Generates Express REST APIs." There, good enough.


ADD FRONTMATTER AT TOP OF FILE:
---
name: api-generator
description: Generates Express REST APIs.
---

RUN: tessl skill review ./skills/api-generator
WAIT FOR RESULTS


49%. Fails the review. And look at what the judge found - SQL injection, hardcoded secrets, base64 instead of hashing, eval, command injection, auth bypass. Every one of those "pragmatic" design choices from the prompt? A security vulnerability.

This is what a quality gate for AI context looks like. Tessl catches these problems at the source - before a single line of app code gets generated.


Let's fix this. Tessl has a tile-creator - itself a reviewed, scored tile - that helps you build proper tiles. Let me install it and ask Claude Code to take this prompt and turn it into something production-worthy.


RUN: tessl install tessl-labs/tile-creator


tile-creator is itself a tile from the Tessl registry. A reviewed skill that knows how to build other skills properly.


TYPE IN CLAUDE CODE:

Using tile-creator skill, take our uber-prompt.md and create a proper tile out of it. Fix all the issues sonar analysis found. Codify best practices in security and code quality as rules. Instruct the skill to use tessl registry to find, install and use tessl tiles for the dependencies when writing code. The tile should be named jbaruch/api-generator. Put the tile in tiles/api-generator.


WAIT FOR CLAUDE CODE TO WORK - THIS IS THE BIG MOMENT
NARRATE WHAT'S HAPPENING WHILE IT WORKS:


Look at what's happening here. Claude has the Sonar findings in context, and it's using the tile-creator skill to turn those findings into prevention. Rules that fire before code is generated, not after. That's shifting left on AI-generated code quality.


WHEN TILE IS CREATED, RUN: tessl skill review ./tiles/api-generator/skills/api-generator
WAIT FOR RESULTS


From 49% to 100%. From "contains severe security vulnerabilities" to "demonstrates best practices across all dimensions." Same concept, properly structured.


Now let's use this tile to rebuild the same app and see what SonarQube thinks.


TYPE IN CLAUDE CODE:

Using the newly created tile, recreate the app. Delete the old src/ and write a new one. Same task tracker - tasks with title, description, status, assignee, priority. Include authentication, search/filter, export, import, report.


WAIT FOR CODE GENERATION


Same app. Same features. Let's see if the tile makes a difference.


TYPE: COMMIT AND PUSH TO GITHUB
WAIT FOR PUSH


TYPE: SEARCH FOR ALL SONARQUBE ISSUES IN THE JBARUCH_TESSL-DEMO PROJECT IN THE SRC FILES.

SWITCH TO SONARCLOUD BROWSER - DASHBOARD SHOULD SHOW ISSUES RESOLVED
WAIT FOR CLEAN DASHBOARD


65 issues down to zero. Thirteen security blockers - gone. SQL injection, command injection, eval, path traversal, hardcoded secrets - all gone.

Same app. Same features. Same AI. The only difference is the context that guided it. A reviewed, scored tile instead of a random prompt from the internet.


Now that we've verified it works, let's publish it.


RUN: tessl tile publish tiles/api-generator
SWITCH TO BROWSER, SHOW REGISTRY PAGE
POINT AT: 100% SCORE, 11/11 VALIDATION, SECURITY RULES


When we publish to the Tessl registry, every tile gets scored. Review score, validation checks - all visible before anyone installs it. No more blind trust.


Here's the takeaway. AI coding assistants are force multipliers. They multiply whatever patterns you give them - good or bad.

Tessl makes sure the patterns are good before they reach your codebase. SonarQube validates the output. Together, they close the loop on AI code quality.

Everything you saw today is in a public GitHub repo - jbaruch/tessl-demo. Go to tessl.io to start building reviewed, scored tiles for your team.

Thank you.
